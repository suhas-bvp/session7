{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhas-bvp/session7/blob/master/experiment1_CIFAR_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c81c64d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d976285f-769d-42fe-cad4-bff9188c085d"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import ssl\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Bypass SSL certificate verification for dataset download\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "# Function to create a ResNet-50 model for CIFAR-100\n",
        "# - Uses torchvision's resnet50 implementation (deeper than resnet18)\n",
        "# - Sets output layer to 100 classes (CIFAR-100)\n",
        "# - No pre-trained weights are used\n",
        "# - Returns the model\n",
        "def get_resnet(num_classes=100):\n",
        "    model = torchvision.models.resnet50(weights=None)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# Function to create data loaders for CIFAR-100\n",
        "# - Applies advanced data augmentation and normalization for training\n",
        "# - Normalizes test data\n",
        "# - Returns train and test data loaders\n",
        "# - Downloads data if not present\n",
        "# - Uses batch size 128 for training, 100 for testing\n",
        "# - Uses 2 worker threads for loading data\n",
        "def get_dataloaders(batch_size=128):\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.RandomErasing(p=0.5, scale=(0.02, 0.2)),\n",
        "        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "    ])\n",
        "    trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "    return trainloader, testloader\n",
        "\n",
        "# CutMix implementation for regularization\n",
        "def cutmix_data(x, y, alpha=1.0):\n",
        "    '''\n",
        "    Returns mixed inputs, pairs of targets, and lambda\n",
        "    '''\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
        "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return x, y_a, y_b, lam\n",
        "\n",
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = int(W * cut_rat)\n",
        "    cut_h = int(H * cut_rat)\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "# Function to train and evaluate the model\n",
        "# - Performs training and validation (testing) for a specified number of epochs\n",
        "# - Uses label smoothing, CutMix, cosine annealing, and mixed precision\n",
        "# - Logs training and test loss/accuracy to a file and prints to console\n",
        "# - Saves the best model based on test accuracy\n",
        "def train(model, trainloader, testloader, device, epochs=100, lr=0.1, log_file='training_logs.md'):\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    # Use torch.amp.GradScaler and torch.amp.autocast as per new API (without device_type argument)\n",
        "    scaler = torch.amp.GradScaler() if torch.cuda.is_available() else None\n",
        "    best_acc = 0.0\n",
        "    train_losses, train_accs, test_losses, test_accs = [], [], [], []\n",
        "    with open(log_file, 'w') as f:\n",
        "        f.write('| Epoch | Train Loss | Train Acc (%) | Test Loss | Test Acc (%) |\\n')\n",
        "        f.write('|-------|------------|----------------|-----------|--------------|\\n')\n",
        "        for epoch in range(1, epochs+1):\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            correct_train = 0\n",
        "            total_train = 0\n",
        "            for inputs, targets in tqdm(trainloader, desc=f'Epoch {epoch}/{epochs}'):\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                # Apply CutMix with 50% probability\n",
        "                r = np.random.rand()\n",
        "                if r < 0.5:\n",
        "                    inputs, targets_a, targets_b, lam = cutmix_data(inputs, targets)\n",
        "                    with torch.amp.autocast('cuda', enabled=scaler is not None):\n",
        "                        outputs = model(inputs)\n",
        "                        loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
        "                else:\n",
        "                    with torch.amp.autocast('cuda', enabled=scaler is not None):\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, targets)\n",
        "                optimizer.zero_grad()\n",
        "                if scaler:\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total_train += targets.size(0)\n",
        "                correct_train += predicted.eq(targets).sum().item()\n",
        "            train_loss = running_loss / len(trainloader.dataset)\n",
        "            train_acc = 100. * correct_train / total_train\n",
        "            train_losses.append(train_loss)\n",
        "            train_accs.append(train_acc)\n",
        "            # Validation (test) phase\n",
        "            model.eval()\n",
        "            test_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                for inputs, targets in testloader:\n",
        "                    inputs, targets = inputs.to(device), targets.to(device)\n",
        "                    with torch.amp.autocast('cuda', enabled=scaler is not None):\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, targets)\n",
        "                    test_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = outputs.max(1)\n",
        "                    total += targets.size(0)\n",
        "                    correct += predicted.eq(targets).sum().item()\n",
        "            test_loss = test_loss / len(testloader.dataset)\n",
        "            test_acc = 100. * correct / total\n",
        "            test_losses.append(test_loss)\n",
        "            test_accs.append(test_acc)\n",
        "            # Log results to file and print to console\n",
        "            f.write(f'| {epoch} | {train_loss:.4f} | {train_acc:.2f} | {test_loss:.4f} | {test_acc:.2f} |\\n')\n",
        "            print(f'Epoch {epoch}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.2f}%, Test Loss={test_loss:.4f}, Test Acc={test_acc:.2f}%')\n",
        "            # Save best model\n",
        "            if test_acc > best_acc:\n",
        "                best_acc = test_acc\n",
        "                torch.save(model.state_dict(), 'best_resnet50_cifar100.pth')\n",
        "            scheduler.step()\n",
        "    # Plot graphs after training\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
        "    plt.plot(range(1, epochs+1), test_losses, label='Test Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss vs Epoch')\n",
        "    plt.legend()\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(range(1, epochs+1), train_accs, label='Train Accuracy')\n",
        "    plt.plot(range(1, epochs+1), test_accs, label='Test Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Accuracy vs Epoch')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_curves.png')\n",
        "    plt.show()\n",
        "\n",
        "# Main function to set up device, data loaders, model, and start training\n",
        "# - Uses GPU if available, otherwise CPU\n",
        "def main():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    trainloader, testloader = get_dataloaders()\n",
        "    model = get_resnet().to(device)\n",
        "    train(model, trainloader, testloader, device)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100: 100%|██████████| 391/391 [00:50<00:00,  7.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=5.4650, Train Acc=1.31%, Test Loss=4.7506, Test Acc=1.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100: 100%|██████████| 391/391 [00:49<00:00,  7.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss=4.5531, Train Acc=2.13%, Test Loss=4.6956, Test Acc=4.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100: 100%|██████████| 391/391 [00:49<00:00,  7.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss=4.4018, Train Acc=4.14%, Test Loss=4.2430, Test Acc=7.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100: 100%|██████████| 391/391 [00:49<00:00,  7.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss=4.2938, Train Acc=5.68%, Test Loss=4.0496, Test Acc=9.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100: 100%|██████████| 391/391 [00:49<00:00,  7.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss=4.2416, Train Acc=6.88%, Test Loss=3.9547, Test Acc=10.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100: 100%|██████████| 391/391 [00:47<00:00,  8.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss=4.1841, Train Acc=8.33%, Test Loss=3.8533, Test Acc=13.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100: 100%|██████████| 391/391 [00:48<00:00,  8.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss=4.1423, Train Acc=9.20%, Test Loss=3.9123, Test Acc=13.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100: 100%|██████████| 391/391 [00:47<00:00,  8.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Loss=4.0722, Train Acc=10.63%, Test Loss=3.9339, Test Acc=16.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100: 100%|██████████| 391/391 [00:48<00:00,  8.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss=4.0566, Train Acc=11.45%, Test Loss=3.7845, Test Acc=17.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/100: 100%|██████████| 391/391 [00:48<00:00,  7.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss=4.0205, Train Acc=11.90%, Test Loss=3.6426, Test Acc=19.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/100: 100%|██████████| 391/391 [00:49<00:00,  7.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train Loss=3.9602, Train Acc=13.09%, Test Loss=3.5486, Test Acc=19.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/100:  87%|████████▋ | 340/391 [00:41<00:06,  8.45it/s]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}